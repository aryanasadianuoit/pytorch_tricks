{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_retrain_torch_use_logits_using hooks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNhPqk69KeBOuNum/VDgZK6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3b8427fd7b884bafa9a227e743f016c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01c7755d94484d85b79033f626ee86b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_93a301d4394c4282b37542a342b07fb5",
              "IPY_MODEL_66d435d936c24321a36c46a101dfc031"
            ]
          }
        },
        "01c7755d94484d85b79033f626ee86b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93a301d4394c4282b37542a342b07fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_262ed044d5eb493998f2ad569b8d5386",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54285fb28c93430d9f8a471d96e54ff7"
          }
        },
        "66d435d936c24321a36c46a101dfc031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_691ee1938e134b8f871e1c80bf16bdce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 15860001.10it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_425e77e8ba0849ba91e54eb50d7dc481"
          }
        },
        "262ed044d5eb493998f2ad569b8d5386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54285fb28c93430d9f8a471d96e54ff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "691ee1938e134b8f871e1c80bf16bdce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "425e77e8ba0849ba91e54eb50d7dc481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0471e19995964251b637d01a229a52bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c359425002b2416d8aee019643934983",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d3037e57c9db4e55818aa2dd64a68222",
              "IPY_MODEL_057c2fe6999348a0ae8c2154130bbba6"
            ]
          }
        },
        "c359425002b2416d8aee019643934983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3037e57c9db4e55818aa2dd64a68222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_184ff939ca9a4924bbe998b2429ad8e0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_882f4790d70e4c85a4bda5260fab7d08"
          }
        },
        "057c2fe6999348a0ae8c2154130bbba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_22888c5f58ab419a9e68a93847cd3c09",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 92.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23c0809dcebb4714ae82e4624c794ac5"
          }
        },
        "184ff939ca9a4924bbe998b2429ad8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "882f4790d70e4c85a4bda5260fab7d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22888c5f58ab419a9e68a93847cd3c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23c0809dcebb4714ae82e4624c794ac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryanasadianuoit/pytorch_tricks/blob/master/resnet_retrain_torch_use_logits_using_hooks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aQTxLozErQG",
        "colab_type": "text"
      },
      "source": [
        "**Exploiting Logits in a pre_trained ResNet Model**\n",
        "\n",
        "In this code snippet, I have used a ResNet18 model, pre_trained with Image-Net for CIFAR10 classification. The main reason for this code,is how to exploit logits or in a more genral way of saying, any intermediate layer activation in Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3kLISP6F-LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import models, transforms,datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1-wzur-FZgp",
        "colab_type": "text"
      },
      "source": [
        "Since the model has been already trained on Imagenet, I have resized the images in CIFAR10 to be the size of Imagenet data-images, i.e., 224 * 224"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyLadHsnGb-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "3b8427fd7b884bafa9a227e743f016c5",
            "01c7755d94484d85b79033f626ee86b6",
            "93a301d4394c4282b37542a342b07fb5",
            "66d435d936c24321a36c46a101dfc031",
            "262ed044d5eb493998f2ad569b8d5386",
            "54285fb28c93430d9f8a471d96e54ff7",
            "691ee1938e134b8f871e1c80bf16bdce",
            "425e77e8ba0849ba91e54eb50d7dc481"
          ]
        },
        "outputId": "ecd373d8-e3d8-47ab-aa85-0be1af1cdb22"
      },
      "source": [
        "train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "train_set = datasets.CIFAR10(\"./dataset\",train= True, transform= train_transform, download= True)\n",
        "test_set = datasets.CIFAR10(\"./dataset\",train= False, transform= test_transform, download= True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b8427fd7b884bafa9a227e743f016c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udjCBo9UFsAA",
        "colab_type": "text"
      },
      "source": [
        "**This is the scheme of pre-trained ResNet-18.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t9_nIxcHqI_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0471e19995964251b637d01a229a52bd",
            "c359425002b2416d8aee019643934983",
            "d3037e57c9db4e55818aa2dd64a68222",
            "057c2fe6999348a0ae8c2154130bbba6",
            "184ff939ca9a4924bbe998b2429ad8e0",
            "882f4790d70e4c85a4bda5260fab7d08",
            "22888c5f58ab419a9e68a93847cd3c09",
            "23c0809dcebb4714ae82e4624c794ac5"
          ]
        },
        "outputId": "4e50a785-1d24-4ca4-de1f-0f8f1967c2b8"
      },
      "source": [
        "base_resnet_model = models.resnet18(pretrained= True, progress= True)\n",
        "\n",
        "print(base_resnet_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0471e19995964251b637d01a229a52bd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INmG-Dv-F0c9",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the last layer of pre-trained ResNet18 has been trained for 1000 class classification task. but in our case, we have to classify unout images to 10 classes in CIFAR10. For this purpose, we have to replace the last layer of ResNet18 with a new layer with 10 output features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud3vV1e7H-qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_resnet_model.fc  = nn.Linear(in_features=512, out_features= 10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubd7gBZYII8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(base_resnet_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpGpGhSxILVH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1183736a-b17c-4ef2-f187-56debd6939dd"
      },
      "source": [
        "for child in base_resnet_model.children():\n",
        "  print(\"CHILD ====> \",child,\"\\n***************************\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CHILD ====>  Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) \n",
            "***************************\n",
            "\n",
            "CHILD ====>  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
            "***************************\n",
            "\n",
            "CHILD ====>  ReLU(inplace=True) \n",
            "***************************\n",
            "\n",
            "CHILD ====>  MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) \n",
            "***************************\n",
            "\n",
            "CHILD ====>  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ") \n",
            "***************************\n",
            "\n",
            "CHILD ====>  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ") \n",
            "***************************\n",
            "\n",
            "CHILD ====>  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ") \n",
            "***************************\n",
            "\n",
            "CHILD ====>  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ") \n",
            "***************************\n",
            "\n",
            "CHILD ====>  AdaptiveAvgPool2d(output_size=(1, 1)) \n",
            "***************************\n",
            "\n",
            "CHILD ====>  Linear(in_features=512, out_features=10, bias=True) \n",
            "***************************\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbiZZ37SGjfw",
        "colab_type": "text"
      },
      "source": [
        "The model except the last newly replaced layer, has already been trained on a ginat Imagenet dataset, So they will generalize well. Therefore, I freeze those layer's parameters, to prevent them from re-training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZFirdPdIncX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for child in base_resnet_model.children():\n",
        "  if child != \"fc\":\n",
        "    child.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDRn0QV0JTHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(base_resnet_model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHrgSBo4Jqko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "684a2cfe-7ae6-4d84-f94d-cddf3f75661f"
      },
      "source": [
        "previous_saved_loss = 0.0\n",
        "device = torch.device(\"cuda\")\n",
        "base_resnet_model.to(device)\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "      # forward + backward + optimize\n",
        "      outputs = base_resnet_model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # print statistics\n",
        "      running_loss += loss.item()\n",
        "      if i % 1562 == 1561: \n",
        "        print('[%d, %5d] loss: %.3f' %\n",
        "          (epoch + 1, i + 1, running_loss / 1562))\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "\n",
        "          for i,data in enumerate(test_loader,0):\n",
        "\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = base_resnet_model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            if i == 1 :\n",
        "              print(predicted)  \n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "              print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "               100 * correct / total))\n",
        "      \n",
        "        \n",
        "\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  1562] loss: 0.152\n",
            "tensor([8, 1, 4, 4, 4, 5, 5, 4, 2, 4, 8, 3, 1, 6, 9, 1, 2, 9, 3, 5, 7, 9, 5, 3,\n",
            "        4, 0, 2, 6, 6, 9, 4, 5], device='cuda:0')\n",
            "Accuracy of the network on the 10000 test images: 93 %\n",
            "[2,  1562] loss: 0.081\n",
            "tensor([9, 0, 1, 6, 0, 3, 7, 7, 9, 8, 5, 8, 4, 2, 6, 5, 6, 9, 4, 9, 6, 9, 3, 4,\n",
            "        7, 3, 2, 5, 2, 4, 2, 6], device='cuda:0')\n",
            "Accuracy of the network on the 10000 test images: 87 %\n",
            "[3,  1562] loss: 0.044\n",
            "tensor([8, 3, 2, 9, 2, 3, 8, 7, 6, 2, 4, 8, 1, 9, 6, 6, 6, 9, 9, 6, 8, 6, 6, 8,\n",
            "        2, 8, 0, 0, 0, 4, 4, 8], device='cuda:0')\n",
            "Accuracy of the network on the 10000 test images: 93 %\n",
            "[4,  1562] loss: 0.027\n",
            "tensor([3, 6, 1, 1, 1, 9, 4, 6, 5, 1, 0, 2, 7, 1, 4, 1, 2, 4, 7, 8, 8, 7, 0, 9,\n",
            "        2, 3, 2, 3, 7, 7, 2, 8], device='cuda:0')\n",
            "Accuracy of the network on the 10000 test images: 96 %\n",
            "[5,  1562] loss: 0.017\n",
            "tensor([6, 7, 9, 2, 7, 7, 5, 5, 2, 1, 3, 5, 9, 6, 1, 8, 8, 6, 2, 4, 5, 6, 1, 8,\n",
            "        3, 1, 9, 8, 1, 1, 1, 0], device='cuda:0')\n",
            "Accuracy of the network on the 10000 test images: 96 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHAnjRzRHI78",
        "colab_type": "text"
      },
      "source": [
        "Now it's time to use **hook** to exploit the outputs of any required intermediate layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA2hSzYkCtw5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9976c3cf-6bfa-44e8-8f50-15215175d952"
      },
      "source": [
        "activation = {}\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "\n",
        "\n",
        "base_resnet_model.fc.register_forward_hook(get_activation('fc'))\n",
        "#x = torch.randn(1, 25)\n",
        "#\n",
        "\n",
        "logits = [[]]\n",
        "\n",
        "for i,data in enumerate(test_loader,0):\n",
        "  images, labels = data\n",
        "  images, labels = images.to(device), labels.to(device)\n",
        "  outputs = base_resnet_model(images)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  if i == 1 :\n",
        "    print(predicted)  \n",
        "    logits = activation['fc']\n",
        "    print(logits)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "     100 * correct / total))\n",
        "    print(\"*****************\\n\\n\\n\")\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    print(probs)\n",
        "    print(\"*****************\\n\\n\\n\")\n",
        "    _, preds = torch.max(probs, 1)\n",
        "    print(preds)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([6, 2, 9, 0, 8, 1, 0, 8, 4, 6, 9, 7, 7, 7, 0, 1, 5, 0, 5, 5, 6, 2, 9, 2,\n",
            "        1, 6, 4, 4, 8, 9, 8, 9], device='cuda:0')\n",
            "tensor([[-3.7331e+00, -1.3730e+00,  1.1711e+00,  2.7021e+00, -1.7922e+00,\n",
            "         -1.0524e+00,  1.6344e+01, -1.8513e+00, -4.2315e+00, -4.3397e+00],\n",
            "        [ 7.6460e-01, -1.4557e+00,  6.9749e+00, -3.9320e-01, -2.9899e+00,\n",
            "         -2.1957e+00,  4.5609e+00, -2.7747e+00,  1.4060e+00, -4.1557e+00],\n",
            "        [-2.1042e+00,  2.6190e+00, -4.5435e+00,  4.2004e+00, -5.1583e+00,\n",
            "         -1.7244e+00, -5.8664e+00, -1.4226e+00,  5.1304e+00,  9.2242e+00],\n",
            "        [ 1.1929e+01, -8.8369e-01,  4.1632e+00,  1.5992e+00, -1.9542e+00,\n",
            "         -2.4676e+00, -5.1772e+00, -1.4144e+00, -1.5531e+00, -3.2480e+00],\n",
            "        [ 1.7679e-01, -3.1631e+00, -1.5332e+00, -1.5622e+00,  2.6856e+00,\n",
            "         -2.0327e+00, -2.1232e+00, -3.1344e+00,  1.2942e+01, -3.3473e+00],\n",
            "        [-2.7848e+00,  1.0757e+01,  4.6447e-01, -3.2248e+00, -1.8374e-01,\n",
            "         -1.0210e+00, -3.6931e+00, -9.0454e-01, -1.9240e+00,  1.1498e+00],\n",
            "        [ 1.2538e+01, -2.3593e+00, -1.6071e+00,  1.2125e+00, -2.7754e+00,\n",
            "          1.0321e+00, -2.3503e+00, -5.7254e+00,  5.5349e-01, -3.3843e-01],\n",
            "        [-7.0516e-01,  2.7045e-01, -1.7254e+00, -2.4934e+00, -3.0969e+00,\n",
            "         -1.8911e+00,  5.6942e-02, -3.3637e+00,  1.0606e+01,  1.0165e+00],\n",
            "        [-2.6238e+00, -3.2680e+00,  5.9484e+00,  4.0451e+00,  1.0124e+01,\n",
            "         -3.8465e+00, -1.1033e+00,  1.4950e+00, -4.3063e+00, -6.1301e+00],\n",
            "        [-2.4907e+00, -7.2419e-01, -1.4357e+00,  4.7360e-01, -1.9999e+00,\n",
            "         -1.2731e+00,  2.1376e+01, -4.3214e+00, -4.8989e+00, -2.2328e+00],\n",
            "        [-5.8026e-02,  6.4052e-01, -1.9578e+00, -1.9873e-01,  1.5861e-01,\n",
            "          2.2305e+00, -5.0260e+00,  3.7155e+00, -5.1902e+00,  6.4476e+00],\n",
            "        [-2.4525e+00, -1.6695e+00, -2.3495e+00, -2.2519e+00,  3.5385e+00,\n",
            "          1.5919e+00, -3.1897e+00,  1.2216e+01, -4.6855e+00, -1.6658e+00],\n",
            "        [-1.2306e+00, -3.5486e+00, -3.5905e+00,  1.6858e+00, -2.1097e+00,\n",
            "          5.3413e+00, -4.2448e+00,  1.5005e+01, -5.1755e+00, -4.2804e+00],\n",
            "        [-4.4353e+00, -1.5434e+00, -1.4400e+00,  3.1631e-01, -9.5479e-02,\n",
            "          3.2855e+00, -7.2644e+00,  1.5171e+01, -2.9183e+00, -2.1731e+00],\n",
            "        [ 7.1965e+00,  4.5297e+00, -2.8713e+00,  1.2584e+00, -1.4177e+00,\n",
            "         -5.3660e+00, -2.4006e+00, -5.1485e+00,  3.3995e+00, -1.6173e-01],\n",
            "        [-4.1913e+00,  8.3931e+00, -3.9129e+00,  7.5038e-01, -2.6713e+00,\n",
            "         -1.6243e+00, -4.6505e+00, -2.2252e-01, -2.6961e-01,  5.3259e+00],\n",
            "        [-1.3181e+00, -9.8284e-01,  1.6060e+00,  1.1549e+00, -2.8316e+00,\n",
            "          1.1432e+01, -4.3444e+00, -2.4025e+00, -2.3280e+00, -1.5534e-02],\n",
            "        [ 1.0158e+01, -4.3758e+00,  5.6159e+00, -2.7103e-01,  1.2154e+00,\n",
            "         -3.0252e+00, -3.7392e+00, -3.8279e+00,  6.1471e-01, -3.2064e+00],\n",
            "        [-1.9128e+00, -2.6723e+00,  8.2150e-01,  4.7904e+00, -1.4547e+00,\n",
            "          1.0287e+01, -3.0125e+00, -2.8980e-01, -4.3261e+00,  1.6488e-01],\n",
            "        [-4.2146e+00, -2.5493e+00, -9.4181e-01, -8.7028e-01,  4.3354e+00,\n",
            "          1.1380e+01, -1.3271e+00, -2.4630e+00, -2.6610e+00, -1.2410e+00],\n",
            "        [-7.1788e-01, -1.5066e+00,  3.4550e-01,  6.2164e-01, -4.0421e+00,\n",
            "         -1.6568e+00,  1.3456e+01, -3.0994e+00,  7.1211e-01, -2.2924e+00],\n",
            "        [-4.3137e+00, -3.8196e+00,  7.7091e+00,  3.8507e+00, -4.8298e-01,\n",
            "          2.1830e+00,  3.9619e+00, -9.4827e-01, -3.7783e+00, -1.8645e+00],\n",
            "        [ 3.0850e+00,  1.7608e+00, -3.1493e+00, -1.7358e+00, -1.4527e+00,\n",
            "         -1.5295e+00, -2.2762e+00, -1.0558e+00, -1.7816e+00,  7.7601e+00],\n",
            "        [-1.2943e+00, -2.3153e+00,  1.4650e+01,  1.4286e-01, -1.2723e+00,\n",
            "         -5.1612e-01, -1.5611e-01, -2.4758e+00, -4.2980e+00, -1.8299e+00],\n",
            "        [-1.1034e+00,  1.6308e+01, -2.4520e+00,  1.5656e+00, -2.5006e+00,\n",
            "         -2.7980e+00, -5.9112e+00, -1.1152e+00,  1.6784e-01, -3.3046e+00],\n",
            "        [-8.4151e+00, -9.8284e-01,  2.5766e+00,  5.3590e+00,  3.1947e+00,\n",
            "         -1.2926e+00,  1.2229e+01, -3.2531e+00, -1.4526e+00, -6.2969e+00],\n",
            "        [ 2.3653e+00, -4.3092e+00, -2.7123e+00,  2.8135e-01,  1.2982e+01,\n",
            "         -1.6352e+00, -3.8477e+00,  6.0878e+00, -6.3312e+00, -4.7397e+00],\n",
            "        [-3.0179e+00, -5.2604e+00, -2.6355e+00,  6.2364e+00,  9.7062e+00,\n",
            "          6.3428e+00, -2.8818e-01, -1.3555e+00, -5.0657e+00, -4.7766e+00],\n",
            "        [-4.4371e-01, -8.8359e-01, -2.2257e-01, -7.5858e-02, -5.8354e-01,\n",
            "         -5.5409e+00, -6.5529e-02, -3.1137e+00,  1.0717e+01, -2.5326e+00],\n",
            "        [ 1.2179e+00, -2.3536e+00, -1.6017e+00, -2.9720e+00, -1.6958e+00,\n",
            "         -5.0851e+00, -4.3262e+00,  1.1917e+00, -1.0713e+00,  1.4111e+01],\n",
            "        [ 2.0821e+00, -8.6637e-01, -2.8359e+00,  7.2455e-01, -4.0073e+00,\n",
            "         -2.6452e+00, -2.5779e+00, -3.5980e+00,  1.2028e+01,  1.3899e+00],\n",
            "        [-6.4545e-01, -1.6202e+00,  1.6486e+00, -8.3351e-01, -5.1857e+00,\n",
            "         -4.6092e-01, -5.7397e+00, -9.4935e-02,  2.4435e+00,  1.0205e+01]],\n",
            "       device='cuda:0')\n",
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "*****************\n",
            "\n",
            "\n",
            "\n",
            "tensor([[1.9075e-09, 2.0205e-08, 2.5723e-07, 1.1891e-06, 1.3286e-08, 2.7841e-08,\n",
            "         1.0000e+00, 1.2524e-08, 1.1589e-09, 1.0400e-09],\n",
            "        [1.8321e-03, 1.9892e-04, 9.1211e-01, 5.7561e-04, 4.2895e-05, 9.4906e-05,\n",
            "         8.1596e-02, 5.3194e-05, 3.4794e-03, 1.3369e-05],\n",
            "        [1.1737e-05, 1.3207e-03, 1.0237e-06, 6.4209e-03, 5.5357e-07, 1.7159e-05,\n",
            "         2.7266e-07, 2.3203e-05, 1.6274e-02, 9.7593e-01],\n",
            "        [9.9954e-01, 2.7241e-06, 4.2371e-04, 3.2623e-05, 9.3391e-07, 5.5893e-07,\n",
            "         3.7202e-08, 1.6022e-06, 1.3947e-06, 2.5610e-07],\n",
            "        [2.8578e-06, 1.0129e-07, 5.1687e-07, 5.0211e-07, 3.5123e-05, 3.1368e-07,\n",
            "         2.8652e-07, 1.0424e-07, 9.9996e-01, 8.4246e-08],\n",
            "        [1.3147e-06, 9.9986e-01, 3.3880e-05, 8.4666e-07, 1.7718e-05, 7.6699e-06,\n",
            "         5.3009e-07, 8.6176e-06, 3.1093e-06, 6.7233e-05],\n",
            "        [9.9997e-01, 3.3911e-07, 7.1946e-07, 1.2066e-05, 2.2368e-07, 1.0074e-05,\n",
            "         3.4217e-07, 1.1707e-08, 6.2424e-06, 2.5586e-06],\n",
            "        [1.2239e-05, 3.2467e-05, 4.4122e-06, 2.0470e-06, 1.1195e-06, 3.7383e-06,\n",
            "         2.6225e-05, 8.5729e-07, 9.9985e-01, 6.8460e-05],\n",
            "        [2.8579e-06, 1.5006e-06, 1.5098e-02, 2.2506e-03, 9.8246e-01, 8.4143e-07,\n",
            "         1.3073e-05, 1.7572e-04, 5.3129e-07, 8.5757e-08],\n",
            "        [4.3147e-11, 2.5244e-10, 1.2392e-10, 8.3628e-10, 7.0492e-11, 1.4581e-10,\n",
            "         1.0000e+00, 6.9168e-12, 3.8823e-12, 5.5843e-11],\n",
            "        [1.3745e-03, 2.7639e-03, 2.0563e-04, 1.1941e-03, 1.7070e-03, 1.3554e-02,\n",
            "         9.5629e-06, 5.9838e-02, 8.1147e-06, 9.1935e-01],\n",
            "        [4.2589e-07, 9.3187e-07, 4.7209e-07, 5.2047e-07, 1.7027e-04, 2.4307e-05,\n",
            "         2.0377e-07, 9.9980e-01, 4.5656e-08, 9.3531e-07],\n",
            "        [8.8886e-08, 8.7525e-09, 8.3940e-09, 1.6421e-06, 3.6901e-08, 6.3529e-05,\n",
            "         4.3630e-09, 9.9993e-01, 1.7202e-09, 4.2106e-09],\n",
            "        [3.0551e-09, 5.5077e-08, 6.1078e-08, 3.5371e-07, 2.3432e-07, 6.8887e-06,\n",
            "         1.8046e-10, 9.9999e-01, 1.3928e-08, 2.9343e-08],\n",
            "        [9.1284e-01, 6.3416e-02, 3.8725e-05, 2.4072e-03, 1.6569e-04, 3.1955e-06,\n",
            "         6.2002e-05, 3.9721e-06, 2.0481e-02, 5.8176e-04],\n",
            "        [3.2698e-06, 9.5469e-01, 4.3196e-06, 4.5778e-04, 1.4950e-05, 4.2595e-05,\n",
            "         2.0658e-06, 1.7304e-04, 1.6508e-04, 4.4442e-02],\n",
            "        [2.9017e-06, 4.0574e-06, 5.4025e-05, 3.4408e-05, 6.3877e-07, 9.9989e-01,\n",
            "         1.4072e-07, 9.8112e-07, 1.0569e-06, 1.0675e-05],\n",
            "        [9.8923e-01, 4.8231e-07, 1.0535e-02, 2.9241e-05, 1.2929e-04, 1.8616e-06,\n",
            "         9.1159e-07, 8.3418e-07, 7.0903e-05, 1.5530e-06],\n",
            "        [5.0111e-06, 2.3447e-06, 7.7168e-05, 4.0842e-03, 7.9227e-06, 9.9576e-01,\n",
            "         1.6685e-06, 2.5398e-05, 4.4862e-07, 4.0019e-05],\n",
            "        [1.6864e-07, 8.9169e-07, 4.4497e-06, 4.7796e-06, 8.7136e-04, 9.9911e-01,\n",
            "         3.0269e-06, 9.7208e-07, 7.9744e-07, 3.2991e-06],\n",
            "        [6.9861e-07, 3.1747e-07, 2.0233e-06, 2.6667e-06, 2.5149e-08, 2.7320e-07,\n",
            "         9.9999e-01, 6.4559e-08, 2.9192e-06, 1.4469e-07],\n",
            "        [5.7238e-06, 9.3814e-06, 9.5310e-01, 2.0111e-02, 2.6384e-04, 3.7946e-03,\n",
            "         2.2477e-02, 1.6568e-04, 9.7772e-06, 6.6279e-05],\n",
            "        [9.2108e-03, 2.4504e-03, 1.8063e-05, 7.4243e-05, 9.8541e-05, 9.1256e-05,\n",
            "         4.3249e-05, 1.4655e-04, 7.0920e-05, 9.8780e-01],\n",
            "        [1.1894e-07, 4.2847e-08, 1.0000e+00, 5.0059e-07, 1.2159e-07, 2.5899e-07,\n",
            "         3.7123e-07, 3.6495e-08, 5.8999e-09, 6.9616e-08],\n",
            "        [2.7426e-08, 1.0000e+00, 7.1199e-09, 3.9565e-07, 6.7819e-09, 5.0373e-09,\n",
            "         2.2395e-10, 2.7105e-08, 9.7782e-08, 3.0354e-09],\n",
            "        [1.0808e-09, 1.8261e-06, 6.4176e-05, 1.0370e-03, 1.1907e-04, 1.3397e-06,\n",
            "         9.9878e-01, 1.8861e-07, 1.1415e-06, 8.9876e-09],\n",
            "        [2.4477e-05, 3.0906e-08, 1.5261e-07, 3.0458e-06, 9.9896e-01, 4.4808e-07,\n",
            "         4.9029e-08, 1.0125e-03, 4.0916e-09, 2.0096e-08],\n",
            "        [2.7948e-06, 2.9678e-07, 4.0965e-06, 2.9203e-02, 9.3825e-01, 3.2482e-02,\n",
            "         4.2838e-05, 1.4733e-05, 3.6056e-07, 4.8142e-07],\n",
            "        [1.4219e-05, 9.1584e-06, 1.7738e-05, 2.0541e-05, 1.2363e-05, 8.6932e-08,\n",
            "         2.0754e-05, 9.8465e-07, 9.9990e-01, 1.7606e-06],\n",
            "        [2.5162e-06, 7.0738e-08, 1.5003e-07, 3.8113e-08, 1.3656e-07, 4.6067e-09,\n",
            "         9.8396e-09, 2.4512e-06, 2.5500e-07, 9.9999e-01],\n",
            "        [4.7897e-05, 2.5107e-06, 3.5029e-07, 1.2323e-05, 1.0857e-07, 4.2390e-07,\n",
            "         4.5339e-07, 1.6347e-07, 9.9991e-01, 2.3971e-05],\n",
            "        [1.9387e-05, 7.3149e-06, 1.9222e-04, 1.6064e-05, 2.0689e-07, 2.3316e-05,\n",
            "         1.1888e-07, 3.3620e-05, 4.2561e-04, 9.9928e-01]], device='cuda:0')\n",
            "*****************\n",
            "\n",
            "\n",
            "\n",
            "tensor([6, 2, 9, 0, 8, 1, 0, 8, 4, 6, 9, 7, 7, 7, 0, 1, 5, 0, 5, 5, 6, 2, 9, 2,\n",
            "        1, 6, 4, 4, 8, 9, 8, 9], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_6VARv8EqP5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}